---
title: 'Capstone: IGN Editor''s Choice Award'
author: "Pratyush Pati"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r ign,include=FALSE}
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(caTools)
library(ROCR)

####### Helper Function For Standard Error/CI from R Cookbook ####################
st.err <- function(x) {
    sd(x)/sqrt(length(x))
     }

########## EDA: Data Wrangling #########################

# Obtain original ign dataset
ign <- read.csv("ign.csv", header=TRUE)

# Creation of the wrangled dataset
ign_order <- ign[order(ign$title),]
ign_revised <- ign

# Change class to appropriate types
ign_revised$title <- as.character(ign_revised$title)
ign_revised$genre <- as.character(ign_revised$genre)

# Removed games with missing genre 
ign_revised <- ign_revised %>%
	  filter(genre != "")

# Filter for games in certain 5 year period (2012-2016)
year_start <- 2012
year_end <- 2016

ign_revised <- ign_revised %>% 
	  filter(release_year >= year_start & release_year <= year_end)

# Filter games released on multiple platform
multiple_platform <- ign_revised[duplicated(ign_revised$title) | duplicated(ign_revised$title, fromLast=TRUE),]

# Obtain the distinct game platform and order alphabetically
dis_platform <- as.character(unique(ign_revised$platform)) 
dis_platform <- sort(dis_platform)

# Removing duplicate title games in main dataset
ign_revised <- ign_revised[!duplicated(ign_revised$title),]

# Order videogames alphabetically
ign_revised <- ign_revised[order(ign_revised$title),]
multiple_platform <- multiple_platform[order(multiple_platform$title),]

# Add distinct platform list as columns to main dataset
ign_revised[dis_platform] <- as.list(dis_platform)

# Original dataset showing only title and platform
ign_temp <- ign %>% filter(!is.na(genre)) %>% 
	  filter(release_year >= year_start & release_year <= year_end) %>% 
    select(title, platform) 

# Applying 1 (Yes) or 0 (No) to games if they appear in the platform columns
ign_temp$value = 1
ign_temp_wide = reshape2::dcast(title ~ platform, data = ign_temp,
                           value.var = "value", fill = 0)

ign_revised <- merge(ign_revised[1:11], ign_temp_wide, by = "title")

# Remove the old platform column, and unused x1, url columns
ign_revised <- ign_revised %>% 
               select(-platform)  
ign_revised <- ign_revised %>% 
               select(-X1)
ign_revised <- ign_revised %>% 
               select(-url)

# Total Sum of Platform winner of editors award in tidyr form
df_won <- ign_revised %>% filter(editors_choice == "Y") %>% 
  select(Android:`Xbox One`) %>% 
  summarise_each(funs(sum))

df_lost <- ign_revised %>% filter(editors_choice == "N") %>% 
  select(Android:`Xbox One`) %>% 
  summarise_each(funs(sum))

tot_platform <- rbind(df_won, df_lost)
rownames(tot_platform) <- c("Won", "Lost")

tot_platform["award"] <- rownames(tot_platform)
tot_platform <- melt(tot_platform, id.vars="award", 
                value.name="Games", variable.name="Platform")

# Total Sum of Platform winner of editors award in horizontal form
won_sum <- t(df_won)
lost_sum <- t(df_lost)
colnames(won_sum) <- c("Won")
colnames(lost_sum) <- c("Lost")
tot_platform_2 <-  merge(won_sum, lost_sum, by=0, all=TRUE)
colnames(tot_platform_2) <- c("Platform", "Won", "Lost")
tot_platform_2$Platform <- as.character(tot_platform_2$Platform)
tot_platform_2$Won <- as.numeric(tot_platform_2$Won)
tot_platform_2$Lost <- as.numeric(tot_platform_2$Lost)

tot_plat2_tidy <- ddply(melt(tot_platform_2, id.vars = 'Platform'),
                        .(Platform), mutate, prop = value / sum(value))
tot_plat2_tidy$variable <- as.character(tot_plat2_tidy$variable)
tot_plat2_tidy$value <- as.numeric(tot_plat2_tidy$value)
tot_plat2_tidy$prop <- as.numeric(tot_plat2_tidy$prop)

# New column for total number of platforms game appears on
ign_revised$tot_Plat <- rowSums(ign_revised[,c(9:32)])

# New column for word count of the title
ign_revised$word_count <- sapply(ign_revised$title, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
ign_revised$word_count <- ifelse(grepl("^1$", ign_revised$word_count, ignore.case = T), 1, 
         ifelse(grepl("^2", ign_revised$word_count, ignore.case = T), 2,
         ifelse(grepl("^3", ign_revised$word_count, ignore.case = T), 3,        
         ifelse(grepl("^4", ign_revised$word_count, ignore.case = T), 4,
         ifelse(grepl("^5", ign_revised$word_count, ignore.case = T), 5,
         ifelse(grepl("^6", ign_revised$word_count, ignore.case = T), 6,
         ifelse(grepl("^7", ign_revised$word_count, ignore.case = T), 7,
         ifelse(grepl("^8", ign_revised$word_count, ignore.case = T), 8,
         ifelse(grepl("^9", ign_revised$word_count, ignore.case = T), 9, 10))))))))) # 10+ words classified as 10

# New column for character count of title
ign_revised$char_count <- sapply(ign_revised$title, function(x) nchar(x))

# New column for starting letter/# of title
ign_revised$title_start <- ifelse(grepl("^A", ign_revised$title, ignore.case = T), "A", 
         ifelse(grepl("^B", ign_revised$title, ignore.case = T), "B",
         ifelse(grepl("^C", ign_revised$title, ignore.case = T), "C",        
         ifelse(grepl("^D", ign_revised$title, ignore.case = T), "D",
         ifelse(grepl("^E", ign_revised$title, ignore.case = T), "E",
         ifelse(grepl("^F", ign_revised$title, ignore.case = T), "F",
         ifelse(grepl("^G", ign_revised$title, ignore.case = T), "G",
         ifelse(grepl("^H", ign_revised$title, ignore.case = T), "H",
         ifelse(grepl("^I", ign_revised$title, ignore.case = T), "I",
         ifelse(grepl("^J", ign_revised$title, ignore.case = T), "J",
         ifelse(grepl("^K", ign_revised$title, ignore.case = T), "K",
         ifelse(grepl("^L", ign_revised$title, ignore.case = T), "L",
         ifelse(grepl("^M", ign_revised$title, ignore.case = T), "M",
         ifelse(grepl("^N", ign_revised$title, ignore.case = T), "N",
         ifelse(grepl("^O", ign_revised$title, ignore.case = T), "O",
         ifelse(grepl("^P", ign_revised$title, ignore.case = T), "P",
         ifelse(grepl("^Q", ign_revised$title, ignore.case = T), "Q",
         ifelse(grepl("^R", ign_revised$title, ignore.case = T), "R",
         ifelse(grepl("^S", ign_revised$title, ignore.case = T), "S",
         ifelse(grepl("^T", ign_revised$title, ignore.case = T), "T",
         ifelse(grepl("^U", ign_revised$title, ignore.case = T), "U",
         ifelse(grepl("^V", ign_revised$title, ignore.case = T), "V",
         ifelse(grepl("^W", ign_revised$title, ignore.case = T), "W",
         ifelse(grepl("^X", ign_revised$title, ignore.case = T), "X",
         ifelse(grepl("^Y", ign_revised$title, ignore.case = T), "Y",
         ifelse(grepl("^Z", ign_revised$title, ignore.case = T), "Z","#"))))))))))))))))))))))))))

# New column for games with numbers (sequel) in title
ign_revised$number <- ifelse(grepl(".*([0-9]+)", ign_revised$title, ignore.case = T), "Yes","No")

# New column for games with franchise name in title
ign_revised$franchise <- ifelse(grepl("Mario", ign_revised$title, ignore.case = T), "Mario", 
         ifelse(grepl("Zelda", ign_revised$title, ignore.case = T), "Zelda",
         ifelse(grepl("Pokemon", ign_revised$title, ignore.case = T), "Pokemon",        
         ifelse(grepl("Halo", ign_revised$title, ignore.case = T), "Halo",
         ifelse(grepl("LEGO", ign_revised$title, ignore.case = T), "LEGO",
         ifelse(grepl("Star Wars", ign_revised$title, ignore.case = T), "Star Wars",
         ifelse(grepl("Call of Duty", ign_revised$title, ignore.case = T), "Call of Duty",
         ifelse(grepl("FIFA", ign_revised$title, ignore.case = T), "FIFA",
         ifelse(grepl("^NBA", ign_revised$title, ignore.case = T), "NBA",
         ifelse(grepl("Grand Theft Auto", ign_revised$title, ignore.case = T), "Grand Theft Auto",
         ifelse(grepl("Tom Clancy", ign_revised$title, ignore.case = T), "Tom Clancy",
         ifelse(grepl("Street Fighter", ign_revised$title, ignore.case = T), "Street Fighter",
         ifelse(grepl("Warcraft", ign_revised$title, ignore.case = T), "Warcraft",
         ifelse(grepl("Resident Evil", ign_revised$title, ignore.case = T), "Resident Evil",
         ifelse(grepl("Metal Gear", ign_revised$title, ignore.case = T), "Metal Gear",
         ifelse(grepl("Dark Souls", ign_revised$title, ignore.case = T), "Dark Souls",
         ifelse(grepl("Forza", ign_revised$title, ignore.case = T), "Forza",
         ifelse(grepl("Final Fantasy", ign_revised$title, ignore.case = T), "Final Fantasy",
         ifelse(grepl("Uncharted", ign_revised$title, ignore.case = T), "Uncharted","Other")))))))))))))))))))

# New column for top 10 genre
ign_revised$top_genre <- ifelse(grepl("^Action", ign_revised$genre, ignore.case = T), "Action", 
         ifelse(grepl("^Adventure", ign_revised$genre, ignore.case = T), "Adventure",
         ifelse(grepl("^Fighting", ign_revised$genre, ignore.case = T), "Fighting",        
         ifelse(grepl("^Platformer", ign_revised$genre, ignore.case = T), "Platformer",
         ifelse(grepl("^Racing", ign_revised$genre, ignore.case = T), "Racing",
         ifelse(grepl("^RPG", ign_revised$genre, ignore.case = T), "RPG",
         ifelse(grepl("^Shooter", ign_revised$genre, ignore.case = T), "Shooter",
         ifelse(grepl("^Sports", ign_revised$genre, ignore.case = T), "Sports",
         ifelse(grepl("^Strategy", ign_revised$genre, ignore.case = T), "Strategy","Other")))))))))
```

## I. Purpose

The purpose of this capstone project was to find what variables of a video game will allow us to predict if the game will win an IGN Editor's Choice award through a logistic regression model.

## II. Client Analysis

The main client for this problem would be game studios and their developers. In the videogame industry, most of the success of developer companies is measured by the rating of their games and the awards they receive. These achievements not only allow more consumers to buy their games and profit more, but also receive funding and partnership with major publishers for future projects and development. By understanding what characteristics of a certain video game allow it possibly to win one of these prestigious award, The Editor’s Choice award from the videogame review website IGN, game developers will be able to know if their game will be successful as well as what type of project they should pursue to earn this achievement in the future.

## III. Dataset

The dataset used for this project is from Kaggle, specifically from the dataset provided in 20 Years of Games by Eric Grinstein (https://www.kaggle.com/egrinstein/20-years-of-games). The dataset includes 18,625 video games reviews from IGN that range from games released from 1996-2016 in a csv file format, in which, 3,517 were winners of the Editor's Choice award (18.88%) and 15,108 were non-winners (81.12%).

#### Original Variables:
  + **X1**: a numerical indicator for each videogame
  + **Score_phrase**: one word description of the videogame as a factor of either Amazing, Awful, Bad, Disaster, Good, Great, Masterpiece, Mediocre, Okay, Painful, Unbearable
  + **Title**: video game's main name
  + **Url**: an IGN’s URL link to the video game review
  + **Platform**: videogame console released by publishers such as Nintendo, Sony, Microsoft, etc.
  + **Score**: scoring system of the video game which are decimal values ranging from of 0 to 10
  + **Genre**: video game’s category or style
  + **Editor_choice**: video game has won (Y) or not won (N) the editor's choice award
  + **Release_year**: year videogame was released on
  + **Release_month**: month videogame was released on
  + **Release_day**: day videogame was released on 
  
#### New Introduced Variables:
  + **Tot_Plat**: total number of platforms the videogame is released on
  + **Word_count**: total number of words in the videogame title
  + **Char_count**: total number of characters in the videogame title
  + **Title_start**: the starting letter of the videogame title (#,A-Z)
  + **Number**: videogame contains a number in the title
  + **Franchise**: videogame contains a certain franchise name in the title
  + **Top_genre**: videogame's genre is a top 10 genre

## IV. Exploratory Data Analysis (EDA) 

#### Dataset Wrangling:

The dataset wrangling process was started by creating a new dataframe called *ign_revised*, which is the copy of the original dataset, *ign*, but with the wrangled revisions. To clean the data, games with blank **genre** were removed and dataset was filtered to only include games with **release_year** from a 5 year period (2012 to 2016) to focus on a specific sample size from the entire dataset. Also, the **X1** and **url** variable were removed since they were not needed for this project. To avoid video games being repeated on multiple rows due to numerous platform releases, **platform** column was removed and replaced with new columns for each unique platform indicating a 1 (game was released on that platform) or 0 (if not). The new introduced variables, as stated above, were also appended to *ign_revised*. In the dataset there were a few games that exceeded 10 words for the game title and were merged into the group of 10 word count to reduce the complexity level for the model. Both the **Franchise** and **Top_genre** variables were constructed from IGN's database of the top successful franchise names and genres. After the cleaning the dataset, *ign_revised* consisted of 1,612 games where 290 were winners of the Editor's Choice Award (17.99%) and 1322 non-winners (82.01%).

#### Predicted Variable: Editor's Choice Award

The following is a breakdown of the model training dataset constructed from *ign_revised* of games that won (1) or lost (0) the Editor's Choice award:

```{r EC_Train_breakdown, echo=FALSE}
# Creating model training and testing set
# Make Y=1, N = 0 for LR to work
ign_revised_2 <- ign_revised
ign_revised_2$editors_choice <- ifelse(grepl("Y", ign_revised_2$editors_choice, ignore.case = T), 1,0)

set.seed(500)
split = sample.split(ign_revised_2$editors_choice, SplitRatio = 0.75)
EC_Train = subset(ign_revised_2, split == TRUE)
EC_Test = subset(ign_revised_2, split == FALSE)
table(EC_Train$editors_choice)

```

#### EDA Plot Analysis: 

1) The EDA plot below displays the proportion of Editor's Choice award winners by **Platform** from 2012-2016. There are a total of 24 platforms during this time period and had an overall average proportion of 0.2616 of winners. One of the interesting observations were that both the Nintendo DS and SteamOS had games that all won the Editor's Choice award, both of which have been very successful platforms during this period. Contrastingly, platforms such as the Arcade, Nintendo Dsi, Web Games, Windows Phone and Windows Surface didn't have any winners, probably due to being older platforms or less popular with the public. Additionally, the Ouya didn't have any winners as well probably due to being a relative new console.


```{r EDA_Platform, echo=FALSE}
# Plotting Proportion of Editor's Choice award won per Platform w/ Error Bar 
prop_Platform_EC <- tot_plat2_tidy 
prop_Platform_EC$SE <- sqrt(prop_Platform_EC$prop*(1-prop_Platform_EC$prop)/sum(prop_Platform_EC$value)) #SE of prop
prop_Platform_EC_won <- prop_Platform_EC %>% 
                        filter(variable == 'Won')
avg_Platform_EC_won <- mean(prop_Platform_EC_won$prop)
ggplot(prop_Platform_EC_won, aes(x = Platform, y = prop)) + 
  geom_point(col = "Blue") +
  geom_errorbar(aes(ymin=prop-SE, ymax=prop+SE), width=0.2, colour="black") +
  geom_hline(yintercept = avg_Platform_EC_won, linetype="dashed", color = "red") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(hjust = 0.5, line = 4, face="bold")) +
        scale_y_continuous(expand = c(0, 0), limits = c(0, 1.1)) +
        labs(title = "Proportion of Editor's Choice Award by Platform \n from 2012-2016", 
             x = "Platform", 
             y = "Proportion of Winners") + 
  theme(plot.title = element_text(lineheight=1)) #space between title
```

2) The EDA plot below displays the proportion of Editor's Choice award winners by **Top_Genre** from 2012-2016. The variable **Top_Genre** was revised from the original variable **Genre** in order to reduce the number of levels for the model as well as reducing the complexity of a game categorized with numerous types to a single main genre. The final dataset was broken down into 10 main genres with an overall average proportion of 0.1908 of winners. The plot revealed that Racing genre saw the greatest proportion of Editor's Choice winners followed by Platformer and RPG (Role Playing Games) games. Contrastingly, Sports had the lowest proportion of winners.

```{r EDA_TopGenre, echo=FALSE}
# Plotting Proportion of Editor's Choice award won per Top Genre w/ Error Bar
prop_Top_Genre_EC <- ign_revised %>%
                      group_by(top_genre, editors_choice) %>%
                      summarise (n = n()) %>%
                      mutate(freq = n / sum(n))
prop_Top_Genre_EC$SE <- sqrt(prop_Top_Genre_EC$freq*(1-prop_Top_Genre_EC$freq)/sum(prop_Top_Genre_EC$n)) #SE of prop
prop_Top_Genre_EC_won <- prop_Top_Genre_EC %>% 
                        filter(editors_choice == 'Y')
avg_Top_Genre_EC_won <- mean(prop_Top_Genre_EC_won$freq)
ggplot(prop_Top_Genre_EC_won, aes(x = top_genre, y = freq)) + 
  geom_point(col = "Blue") +
  geom_errorbar(aes(ymin=freq-SE, ymax=freq+SE), width=0.2, colour="black") +
  geom_hline(yintercept = avg_Top_Genre_EC_won, linetype="dashed", color = "red") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(hjust = 0.5, line = 4, face="bold")) +
        scale_y_continuous(expand = c(0, 0), limits = c(0, 1.1)) +
        labs(title = "Proportion of Editor's Choice Award by Top Genres \n from 2012-2016", 
             x = "Top Genres", 
             y = "Proportion of Winners") + 
  theme(plot.title = element_text(lineheight=1))
```

3) The EDA plot below displays the proportion of editor's choice award winners by **Franchise** in the game's title from 2012-2016. The dataset has the top 20 leading franchise names with an overall average proportion of 0.4119 of winners.The plot revealed that games with Warcraft in their title all won Editor's Choice awards followed by high proportion winners from leading franchise such as Forza, Uncharted, Halo, Dark Souls and Metal Gear, respectively. Contrastingly, Resident Evil had the lowest proportion of winners followed by FIFA and Star Wars.

```{r Franchise, echo=FALSE}
# Plotting Proportion of Editor's Choice award won per Franchise w/ Error Bar
prop_Fran_EC <- ign_revised %>%
                      group_by(franchise, editors_choice) %>%
                      summarise (n = n()) %>%
                      mutate(freq = n / sum(n))
prop_Fran_EC$SE <- sqrt(prop_Fran_EC$freq*(1-prop_Fran_EC$freq)/sum(prop_Fran_EC$n)) #SE of prop
prop_Fran_EC_won <- prop_Fran_EC %>% 
                        filter(editors_choice == 'Y')
avg_Fran_EC_won <- mean(prop_Fran_EC_won$freq)
ggplot(prop_Fran_EC_won, aes(x = franchise, y = freq)) + 
  geom_point(col = "Blue") +
  geom_errorbar(aes(ymin=freq-SE, ymax=freq+SE), width=0.2, colour="black") +
  geom_hline(yintercept = avg_Fran_EC_won, linetype="dashed", color = "red") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(hjust = 0.5, line = 4, face="bold")) +
        scale_y_continuous(expand = c(0, 0), limits = c(0, 1.1)) +
        labs(title = "Proportion of Editor's Choice Award by Franchise \n from 2012-2016", 
             x = "Franchise", 
             y = "Proportion of Winners") + 
  theme(plot.title = element_text(lineheight=1))
```

4) The EDA plot below displays the distribution of the total number of platform releases for games, **Tot_Plat**, in regards to winning the Editor's Choice award from 2012-2016. Even though the spread was similar between winners and non-winners, the plot revealed that the winners of the award had a median of 1 and mean of 1.921 and non-winners had a median of 1 and mean of 1.523 platform releases. Also, award winning games had fewer outliers of total platform releases compared to non-winners, indicating it was best to use the total release numbers from the award winner’s IQR.

Editor's Choice Award Winner Boxplot Summary:
```{r TP, echo=FALSE}
# Box Plot Summary of Winners
df_TP_Summary <- ign_revised %>% 
            select(editors_choice, tot_Plat) %>%
	          filter(editors_choice == "Y")
summary(df_TP_Summary$tot_Plat)

# Box Plotting Total Number of Platform Releases for Games Winning Editor's Choice Award
ggplot(ign_revised, aes(x = editors_choice, y = tot_Plat, group = factor(editors_choice))) + 
  geom_boxplot() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(hjust = 0.5, line = 4, face="bold")) +
        scale_y_continuous(expand = c(0, 0), breaks = seq(0,10,by = 1), limits = c(0, 10.5)) +
        labs(title = "Total Number of Platform Releases for Games \n Winning Editor's Choice Award from 2012-2016", 
             x = "Editor's Choice Award", 
             y = "Total Number of Platform Releases") + 
  theme(plot.title = element_text(lineheight=1))

```

5) The EDA plot below displays the distribution of the total word count of the game's title, **Word_Count**, in regards to winning the Editor's Choice award from 2012-2016. The plot revealed that the word count spread (IQR) was slightly larger in the award winners compared to non-winners, where the winners plot had a median of 3 and mean of 3.724 and non-winners had a median of 3 and mean of 3.551 word count for the game title. Also, award winning games had fewer outliers of high word count compared to non-winners, indicating it was best to limit the count within the award winner’s IQR.

Editor's Choice Award Winner Boxplot Summary:
```{r WC, echo=FALSE}
# Box Plot Summary of Winners
df_WC_Summary <- ign_revised %>% 
            select(editors_choice, word_count) %>%
	          filter(editors_choice == "Y")
summary(df_WC_Summary$word_count)

# Box Plotting Word Count for Games Winning Editor's Choice Award
ggplot(ign_revised, aes(x = editors_choice, y = word_count, group = factor(editors_choice))) + 
  geom_boxplot() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(hjust = 0.5, line = 4, face="bold")) +
        scale_y_continuous(expand = c(0, 0), breaks = seq(0,10,by = 1), limits = c(0, 10.5)) +
        labs(title = "Word Count of Game Title Winning Editor's Choice Award \n from 2012-2016", 
             x = "Editor's Choice Award", 
             y = "Word Count") + 
  theme(plot.title = element_text(lineheight=1))
```

6) The EDA plot below displays the distribution of the total character count of the game's title, **Char_Count**, in regards to winning the editor's choice award from 2012-2016. The plot revealed that the character count spread (IQR) was slightly larger in the award winners compared to non-winners, where the winners plot had a median of 18 and mean of 21.97 and non-winners had a median of 19 and mean of 21.28 character count for the game title. Also, award winning games had fewer outliers of high character count compared to non-winners, indicating it was best to limit the count within the award winner's IQR.

Editor's Choice Award Winner Boxplot Summary:
```{r CC, echo=FALSE}
# Box Plot Summary of Winners
df_CC_Summary <- ign_revised %>% 
            select(editors_choice, char_count) %>%
	          filter(editors_choice == "Y")
summary(df_CC_Summary$char_count)

# Box Plotting Char Count for Games Winning Editor's Choice Award
ggplot(ign_revised, aes(x = editors_choice, y = char_count, group = factor(editors_choice))) +
  geom_boxplot() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(hjust = 0.5, line = 4, face="bold")) +
        scale_y_continuous(expand = c(0, 0), breaks = seq(0,100,by = 10), limits = c(0, 100)) +
        labs(title = "Character Count of Game Title Winning Editor's Choice Award \n from 2012-2016",
             x = "Editor's Choice Award",
             y = "Character Count") + 
  theme(plot.title = element_text(lineheight=1))
```

7) The EDA plot below displays the proportion of Editor's Choice award winners for games by **Month** from 2012-2016. The plot had an overall average proportion of 0.1773 of winners. Out of all the months, September had the highest proportion of award winners and the December had the lowest.

```{r Month, echo=FALSE}
# Plotting Proportion of Editor's Choice award won per Month w/ Error Bar 
prop_Month_EC <- ign_revised %>%
                      group_by(release_month, editors_choice) %>%
                      summarise (n = n()) %>%
                      mutate(freq = n / sum(n))
prop_Month_EC$SE <- sqrt(prop_Month_EC$freq*(1-prop_Month_EC$freq)/sum(prop_Month_EC$n)) #SE of prop
prop_Month_EC_won <- prop_Month_EC %>% 
                        filter(editors_choice == 'Y')
avg_Month_EC_won <- mean(prop_Month_EC_won$freq)
ggplot(prop_Month_EC_won, aes(x = release_month, y = freq)) + 
  geom_point(col = "Blue") +
  geom_errorbar(aes(ymin=freq-SE, ymax=freq+SE), width=0.2, colour="black") +
  geom_hline(yintercept = avg_Month_EC_won, linetype="dashed", color = "red") +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(hjust = 0.5, line = 4, face="bold")) +
        scale_x_continuous(expand = c(0, 0), breaks = seq(1,12, by = 1), limits=c(0.5,12.5)) +
        scale_y_continuous(expand = c(0, 0), limits = c(0, 1)) +
        labs(title = "Monthly Proportion of Editor's Choice Award \n from 2012-2016", 
             x = "Month", 
             y = "Proportion of Winners") + 
  theme(plot.title = element_text(lineheight=1))
```           

## V. Logistic Regression Models

In order to create and test a logistic regression model, the final database *ign_revised* was split into a training dataset and a testing dataset. A split ratio of 75% was used between the sets in order to see how well the final logistic regression model created from the training set could be used to predict in the testing dataset.

```{r LR_setup, echo=FALSE}
# Creating model training and testing set
# Make Y=1, N=0 for LR to work
ign_revised_2 <- ign_revised
ign_revised_2$editors_choice <- ifelse(grepl("Y", ign_revised_2$editors_choice, ignore.case = T), 1,0)

set.seed(500)
split = sample.split(ign_revised_2$editors_choice, SplitRatio = 0.75)
EC_Train = subset(ign_revised_2, split == TRUE)
EC_Test = subset(ign_revised_2, split == FALSE)

```

##### **Selection of Independent Variables:**

To begin with, the Akaike Information Criterion (AIC) was used to measure the relative quality of the model, where the minimum AIC would be the most optimal. Predictor variables were added or removed in order to minimize the AIC and compare different models attributes. In the end, the final variables were used as the predictor variables of the main logistic regression model.

1) Original Variables: 
The first logistic regression model tested were the original variables from the IGN database to predict a videogame's potential to win an Editor's Choice award. Specifically, **genre**, **release_year**, **release_month**, and **release_day** were only used, while **Score** and **score_phrase** were omitted from the model since developers don't have control of these variables after their game releases. Using the original variables stated above the model yielded a AIC of 1189.2.

2) New variables:
The next logistic regression model tested were the new variables introduced into the database. Even though the model improved the AIC to 1126.2, some of the introduced variables like the platforms Android, Arcade, Ouya and SteamOS showed signs of singularity in the model. 

3) Final variables:
To improve the logistic regression model, multiple tests were conducted with a combination of the old and new predictor variables. Through error pruning, some variables like **release_year** and **release_day** were removed due to over-fitting the model as well as removing certain platforms like Android, Arcade, Ouya and SteamOS to reduce singularities. The new variable **Top_genre** was used over the original variable **Genre** due to a more optimal AIC value as well as reducing the complexity level of the variable. Finally, the variable **Title_start** was removed to maximize the sensitivity of the final model to get the best case to identify a videogame will indeed win the award from any testing dataset. Also, the final model had lowest AIC value of 1125.2, which was 1.0 lower than the new variable model, and improved in other model attributes that are discussed in the following sections.

Model | AIC
- | -
Original | 1189.2
New | 1126.2 
Final | 1125.2

Final Logistic Regression Model Summary:
```{r LR_Selection, echo=FALSE, warning=FALSE}
# Logistic Regression Models of Editor's Choice award

# All Variables 
# EC_LR = glm(editors_choice ~ genre + release_year + release_month + release_day + Android + Arcade + iPad + iPhone + Linux + Macintosh + `New Nintendo 3DS` + `Nintendo 3DS` + `Nintendo DS` + `Nintendo DSi` + Ouya + PC + `PlayStation 3` +`PlayStation 4` + `PlayStation Portable` + `PlayStation Vita` + `SteamOS` + `Web Games` + Wii + `Wii U` + `Windows Phone` + `Windows Surface` + `Xbox 360` + `Xbox One` + tot_Plat + word_count + char_count + title_start + number + franchise + top_genre, data= EC_Train, family = binomial)

# # Original variables
# EC_LR = glm(editors_choice ~ genre + release_year + release_month + release_day, data= EC_Train, family = binomial)

# # New variables
# EC_LR = glm(editors_choice ~ Arcade + Android + iPad + iPhone + Linux + Macintosh + `New Nintendo 3DS` + `Nintendo 3DS` + `Nintendo DS` + `Nintendo DSi` + Ouya + PC + `PlayStation 3` +`PlayStation 4` + `PlayStation Portable` + `PlayStation Vita`+ SteamOS + `Web Games` + Wii + `Wii U` + `Windows Phone` + `Windows Surface` + `Xbox 360` + `Xbox One` + tot_Plat + word_count + char_count + title_start + number + franchise + top_genre, data= EC_Train, family = binomial)

# Final Variables
EC_LR = glm(editors_choice ~ release_month + iPad + iPhone + Linux + Macintosh + `New Nintendo 3DS` + `Nintendo 3DS` + `Nintendo DS` + `Nintendo DSi` + PC + `PlayStation 3` +`PlayStation 4` + `PlayStation Portable` + `PlayStation Vita`+ `Web Games` + Wii + `Wii U` + `Windows Phone` + `Windows Surface` + `Xbox 360` + `Xbox One` + tot_Plat + word_count + char_count + number + franchise + top_genre, data= EC_Train, family = binomial)

summary(EC_LR)
```


##### **Probability Summary of True Outcome:**
The logistic model was then tested on the probability of how well the model could accurately predict the true outcome using the training data sample from our original data. 

1) Original Variables: 
Using only the original variables, the model could only predict an average probability of 0.238 for the actual true winners of the Editor's Choice award and an average probability of 0.167 for the actual non-winners of the award.

2) New Variables: 
Using only the introduced variables, the model improved its prediction to an average probability of 0.307 for the actual true winners of the Editor's Choice award and an average probability of 0.152 for the actual non-winners of the award.

3) Final Variables: 
With the final variables, the model could predict to an average probability of 0.283 for the actual true winners of the Editor's Choice award and an average probability of 0.158 for the actual non-winners of the award.

Final Logistic Regression Model Probability Summary of True Outcome:
```{r LR_ProbSum, echo=FALSE}
# Probability Summary of True Outcome
predictTrain = predict(EC_LR, type = "response")
summary(predictTrain)
tapply(predictTrain, EC_Train$editors_choice, mean) # True Outcome table
```


##### **Confusion Matrix and Statistics:**
From the training set, a confusion matrix was then constructed to find out the accuracy and other statistical attributes for the model. The confusion matrix consists of columns of the predicted cases, while the rows show the actual cases of Editor's Choice award winners and non-winners. The statistical attributes were created from each table value as shown below:

CM | Predicted Non-Winner | Predicted Winner
- | - | -
**Actual Non-Winner** | True Negatives (TN) | False Positive (FP)
**Actual Winner** | False Negatives (FN) | True Positive (TP)

Statistical Derivations:

  * Sensitivity (True Positive Rate): $TP / (TP + FN)$
  * Specificity (True Negative Rate): $TN / (TN + FP)$
  * Accuracy:  $(TN + TP) / (TN + FP + FN + TP)$ 
  * Error Rate:  $(FP + FN) / (TN + FP + FN + TP)$  
 

1) Original Variables: 
The model with original variables yielded a true positive rate (sensitivity) of 0.0412 and a true negative rate (specificity) of 0.998. The accuracy of the logistic regression model was 0.826 and had an error rate of 0.173.

2) New Variables: 
The model with strictly new variables yielded a higher sensitivity of 0.178 and decreased the specificity to 0.984. The accuracy of the logistic regression model also increased to 0.839 and lowered the error rate to 0.160.

3) Final Variables: 
The model for the final variables yielded a sensitivity of 0.161 and a specificity of 0.989. The accuracy of the logistic regression model also improved to 0.840 and kept the error rate to 0.160.

Model | Sensitivity | Specificity | Accuracy | Error Rate
- | - | - | - | -
Original | 0.0412 | 0.998 | 0.826 | 0.173
New | 0.178 | 0.984 | 0.839 | 0.160
Final | 0.161 | 0.989 | 0.840 | 0.160

Final Logistic Regression Model Confusion Matrix and Statistics Summary:
```{r LR_CM, echo=FALSE}
# Confusion Matrix
CM_EC <- table(EC_Train$editors_choice, predictTrain > 0.5)

# Sensitivity of CM/True Positive Rate: TP/(TP + FN)
sensitivity = (CM_EC[2,2])/(CM_EC[2,2] + CM_EC[2,1])
# Specificity of CM/True Negative Rate: TN/(TN + FP)
specificity = (CM_EC[1,1])/(CM_EC[1,1] + CM_EC[1,2]) 
# Accuracy: (TN + TP)/N 
accuracy = (CM_EC[1,1] + CM_EC[2,2])/(CM_EC[1,1] + CM_EC[1,2] + CM_EC[2,1] + CM_EC[2,2]) 
# Error Rate: (FP + FN)/N 
error_rate = (CM_EC[1,2] + CM_EC[2,1])/(CM_EC[1,1] + CM_EC[1,2] + CM_EC[2,1] + CM_EC[2,2])

CM_EC
paste("Sensitivity: " , sensitivity)
paste("Specificity: " , specificity)
paste("Accuracy: " , accuracy)
paste("Error Rate: ", error_rate)

```


##### **ROC Curve:**
The Receiver Operator Character (ROC) curve plot was used to help find a threshold that would maximize the sensitivity and specificity for the logistic regression model. ROC curve is plotted below with the sensitivity (true positive rate) on the y-axis and specificity (false positive rate) on the x-axis, where each point on the curve is the threshold rate. The plot also displays how well the model is able to predict the Editor's Choice award, as the closer the ROC curves towards the upper left corner (Point 0,1 being perfect prediction) the better the model. In the ROC plot below, the final logistic regression model is a better than randomly guessing the winner of the award, which would be represented by a diagonal line that would split the graph from the lower left corner to the upper right corner. 
```{r LR_ROC, echo=FALSE}
ROCRpred = prediction(predictTrain, EC_Train$editors_choice)
ROCRpref = performance(ROCRpred, "tpr", "fpr") #true positive and false pos rate
plot(ROCRpref, colorize = TRUE, print.cutoffs.at = seq(0,1,0.1), text.adj = c(-0.2,1.7)) 

```

##### **AUC:**
The area under the ROC curve (AUC) was then used to measure the quality of the model where given a random positive and negative proportion of the time, the model is able to guess correctly when a video game wins the Editor's Choice Award. A minimum baseline AUC of 0.50, representing random guessing, and AUC of 1, representing perfect prediction, were used. 

Model | AUC
- | - 
Original | 0.656
New | 0.756
Final | 0.695

Final Logistic Regression Model AUC value:
```{r LR_AUC, echo=FALSE}
# AUC: positive and negative proportion of prediction
AUC <- as.numeric(performance(ROCRpred, "auc")@y.values)
paste("Area Under Curve (AUC): " , AUC)
```

##### **Testing The Final Logistic Regression Model:**
The final logistic regression model was then used to predict on the model testing data that was split from the original *ign_revised* dataset previously.

The following is a breakdown of the model testing dataset constructed from *ign_revised* of games that won (1) or lost (0) the Editor's Choice award:

```{r EC_Test_breakdown, echo=FALSE}

table(EC_Test$editors_choice)

```

Confusion Matrix and Statistics Summary of testing dataset at threshold = 0.2:
```{r EC_Test_CM, echo=FALSE}

predictTest = predict(EC_LR, type="response", newdata = EC_Test)

CM_EC_test <- table(EC_Test$editors_choice, predictTest > 0.2)

# Sensitivity: TP/(TP + FN)
sensitivity_test = (CM_EC_test[2,2])/(CM_EC_test[2,2] + CM_EC_test[2,1])
# Specificity: TN/(TN + FP)
specificity_test = (CM_EC_test[1,1])/(CM_EC_test[1,1] + CM_EC_test[1,2]) 
# Accuracy: (TN + TP)/N 
accuracy_test = (CM_EC_test[1,1] + CM_EC_test[2,2])/(CM_EC_test[1,1] + CM_EC_test[1,2] + CM_EC_test[2,1] + CM_EC_test[2,2]) 
# Error Rate: (FP + FN)/N 
error_rate_test = (CM_EC_test[1,2] + CM_EC_test[2,1])/(CM_EC_test[1,1] + CM_EC_test[1,2] + CM_EC_test[2,1] + CM_EC_test[2,2])

CM_EC_test
paste("Sensitivity: " , sensitivity_test)
paste("Specificity: " , specificity_test)
paste("Accuracy: " , accuracy_test)
paste("Error Rate: ", error_rate_test)
```

AUC value of testing dataset:
```{r EC_Test_AUC, echo=FALSE}
ROCRpredTest = prediction(predictTest, EC_Test$editors_choice)

AUC_test = as.numeric(performance(ROCRpredTest, "auc")@y.values)
paste("AUC: " , AUC_test)
```

##### **Threshold:**  
Based on these predictor variables, the final regression model was tested to provide the optimum predictor of winning the Editor's Choice award variable due to the attributes in the confusion matrix and AUC values in the testing dataset. By using the ROC curve, different threshold were used to try maximize the sensitivity and specificity while trying to maintain a high accuracy and low error rate. In the table below, three notable thresholds from different sections of the ROC curve plot were used. Starting from the threshold of 0.5, which was used in the training set, the model had the lowest sensitivity and error rate, while having the highest specificity and accuracy out of the three threshold on the testing dataset. Using thresholds higher than 0.5, only made the final model marginally better in specificity, accuracy, and error rate at the cost of worse sensitivity. Using the threshold of 0.1, drastically improved the sensitivity but caused the specificity and accuracy to decrease while having the highest error rate. Similarly, thresholds lower than 0.1 marginally improved sensitivity at the cost of worse specificity, accuracy, and error rate. 

Ultimately, the threshold of 0.2 was used as it balanced the true positive and false positive rate of the model with a relative high sensitivity of 0.444 and specificity of 0.767. This was also supported in the ROC plot where the threshold of 0.2 was the closest point to perfect prediction (upper left corner). The model also had a accuracy of 0.708 and error rate of 0.291. Additionally, regardless of threshold, the model obtained an AUC value of 0.628 which means the final model is able to correctly distinguish between a videogame winner and non-winner of the Editor's Choice Award 62.8% of the time.

Threshold | Sensitivity | Specificity | Accuracy | Error Rate | AUC
- | - | - | - | - | -
0.1 | 0.791 | 0.245 | 0.343 | 0.657 | 0.628
**0.2** | **0.444** | **0.767** | **0.708** | **0.291** | **0.628**
0.5 | 0.167 | 0.973 | 0.828 | 0.160 | 0.628

## VI. Final Logistic Regression Model Results and Analysis

##### **Final Predictor Variables:** 
In summary, the final logistic regression model that was used to predict if a videogame was able to win an Editor's Choice award consisted of the predictor variables:

  + release_month 
  + tot_Plat 
  + word_count 
  + char_count 
  + number 
  + franchise 
  + top_genre
  + iPad 
  + iPhone 
  + Linux 
  + Macintosh 
  + New Nintendo 3DS 
  + Nintendo 3DS
  + Nintendo DS 
  + Nintendo DSi 
  + PC 
  + PlayStation 3 
  + PlayStation 4 
  + PlayStation Portable 
  + PlayStation Vita
  + Web Games 
  + Wii 
  + Wii U 
  + Windows Phone 
  + Windows Surface 
  + Xbox 360 
  + Xbox One 

#### **Recommendations:**
From the results of this final model, we can make some good recommendations for videogame developers to potentially increase their chance to win the Editor's Choice award based on the model summary and statistics. 

##### **Significant Predictor Variables:**

###### **Platforms:**

+ Nintendo 3DS
+ PlayStation Portable
+ iPad
+ iPhone
+ PlayStation Vita
+ Macintosh
+ Wii U

In terms of videogame platforms, the final model revealed that developers should try to release their games on portable gaming systems such as the Nintendo 3DS and PlayStation Portable, which were more likely to win the Editor's Choice award compared to in-home gaming systems. In the last 5 years (2012-2016), this new trend of "gaming on the go" has been heavily popularized in the gaming industry market as seen with an influx of mobile and smartphone application games. Our final model summary suggests that these mobile-type games that appear on systems especially like the iPad, iPhone, and PlayStation Vita are significant winners. However, platforms like the Macintosh and Wii U also suggest that the traditional in-home game consoles still are good options for developers to release their games on as they still have strong established gaming markets. The significance of the Macintosh suggest there is potential for game developers on Apple's desktop and laptop machines which can potentially compete with its main PC console counterpart. The significance of the Wii U also shows potential compared to its main in-home console competitors in PlayStation and Xbox.

###### **Franchise:**

+ Dark Souls
+ Forza
+ Halo
+ Zelda

In terms of videogame franchises, the final model revealed that Dark Souls, Forza, Halo and Zelda were more likely to be Editor's Choice award winners. Developers and publishers that own the rights to these franchises should be motivated to continue on these projects as the model suggests these games will be more successful in awards compared to others. For new videogame developers or developers from different game studios, these four franchises can provide a blueprint of notable styles, features, and game engines that they can incorporate into their own games (within the scope of not infringing copyright or proprietary laws) and possibly have a better chance to be award winners.

###### **Number:**

In terms of a videogame's title, the final model revealed games that had a number in them were more likely to win the Editor's Choice award. This suggests games that offer sequels of their games represented either through a numerical or yearly-based format were more likely to win. Developers can use these annual releases or successive iterations of their games to grow and connect with their consumers, even potentially establishing them as franchise games.

##### **General Predictor Variables:**
The following predictor variables in the logistic regression model were not as significant for the model to predict the Editor's Choice award, but offer suggestions to developers based on the dataset and model summary. The predictor variables **release_month**, **tot_Plat**, and **word_count** were not suggested due to having negative coefficient values in the model, which means they can potentially lead to an outcome of not winning the award.

###### **Top Genre:**

+ Platformer
+ RPG
+ Fighting

In regards to a videogame's genre, the coefficient values of all the top 10 genres were positive indicating that these variables made the game more likely to win the award, besides Shooters and Sports games. The model suggests developers should look into creating games with these popular genres like Platformer, RPG, and Fighting that also have some of the higher positive coefficients. These genres were also some of the top proportion of award winners in our EDA plots from the original dataset.

###### **Character count:**
In regards to a videogame's character count in the title, the positive coefficient value indicates that variable has a positive impact on the game's ability to win the award. Based on the EDA boxplots from the original dataset, the model suggests developers should limit the range of the character count from 11 to 30 (from IQR range) for their game's best chance to win the Editor's Choice award. Having too much characters (potentially words) in the title may confuse consumers and reviewers and cause them not to fully understand the game which may affect winning.

## VII. Further Research
The results from this project are just the beginning of truly understanding how games are judged and awarded in the videogame industry. With annual emerging technologies in new platforms, genres, and game engines the final logistic regression model would need to be improved to better predict the Editor's Choice award from *IGN*. In respect to the original dataset, a more updated game list would be needed especially for games appearing on newer consoles such as Oculus Rift, PlayStation VR and other VR platforms which have a limited sample size in the dataset. Also, some more comprehensive variables like the publishers, gaming studios, and game engines would have been helpful in creating a better predicting model. These variables can give a better understanding of the game, but it was limited in scope of this project since those information were not available for every single game in the database. In terms of a business and monetary perspective, the dataset could be improved by showing how many copies of the videogame have been sold or their sale numbers. This would have helped in research for developers and gaming studios into how much money would be needed to contribute into the success of their games, but would difficult to obtain as gaming publishers don't readily release these numbers into the general public. 

The follow-up research can also be conducted toward on poor performing or discontinued franchise games and platforms, informing developers and game studios on suggestions into which new projects they can potentially work on. For example, one of the bigger news in the gaming industry that occurred during this project was the release of the Nintendo Switch. This console which not only works as a in-home console, but also as a portable gaming system. The Switch would be a great candidate for further research as games on portable consoles were predicted by the model to be more likely winners of the award. In fact, one of Switch's launch titles, The Legend of Zelda: Breath of the Wild, has already earned an Editor's Choice award from IGN (one of the key franchises the model predicted for likely winners as well). 
